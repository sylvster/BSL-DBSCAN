{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density-Based Spatial Clustering of Applications with Noise (DBSCAN)\n",
    "\n",
    "This repository contains the source code to an algorithm that utilizes an unsupervised machine learning algorithm to separate Berkeley Seismology Laboratory's Power Density Function graphs into groups with similar distributions. This is particularly useful in deriving the training dataset for a neural network, since most stations contain a majority of \"correct\" measurements, allowing the DBSCAN's outlier detection to excel at extracting graphs that should be labeled \"erroneous\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from tqdm import tqdm\n",
    "import skimage\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/gcl/TT/sylvesterseo/bsl/strong_motion_incorrects\"\n",
    "output_dir = \"/home/gcl/TT/sylvesterseo/bsl/broadband_ml/batches/\"\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the current working directory to a folder containing all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the type of data to run DBSCAN on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = {\"broadband\": {\"x\": 122,\n",
    "                          \"y\": 151,\n",
    "                          \"xlow\": -1.69897,\n",
    "                          \"xhigh\": 2.854109,\n",
    "                          \"ylow\": -200,\n",
    "                          \"yhigh\": -50,\n",
    "                         },\n",
    "            \"strong_motion\": {\"x\": 114,\n",
    "                              \"y\": 131,\n",
    "                              \"xlow\": -1.69897,\n",
    "                              \"xhigh\": 2.553079,\n",
    "                              \"ylow\": -150,\n",
    "                              \"yhigh\": -20,\n",
    "                             },\n",
    "           }\n",
    "\n",
    "data_type = data_ref[\"strong_motion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used to visualize a PDF file, which is composed of 122 by 151 entries of a probability entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def plotPDF(path):\n",
    "    data = np.fromfile(path, sep=\" \")\n",
    "\n",
    "    # Plot Data\n",
    "    data = np.reshape(data, (data_type[\"x\"] * data_type[\"y\"], 3))\n",
    "    data = np.swapaxes(data, 0, 1)\n",
    "    x = data[0].reshape((data_type[\"x\"], data_type[\"y\"]))\n",
    "    y = data[1].reshape((data_type[\"x\"], data_type[\"y\"]))\n",
    "    z = data[2].reshape((data_type[\"x\"], data_type[\"y\"]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    rainbow = matplotlib.colors.LinearSegmentedColormap.from_list(name=\"rainbow\", colors=['white', 'magenta', 'blue', 'cyan', 'lime', 'yellow', 'orange', 'red'])\n",
    "    c = ax.pcolormesh(x, y, z, cmap=rainbow, vmin=0, vmax=0.30)\n",
    "    ax.set_title(path)\n",
    "    ax.axis([data_type[\"xlow\"], data_type[\"xhigh\"], data_type[\"ylow\"], data_type[\"yhigh\"]])\n",
    "    fig.colorbar(c, ax=ax)\n",
    "\n",
    "    # plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used to visualize multiple PDF files at once, taking the argument of a 2-dimensional array composed of file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGroupPDF(paths, batch, rows=5, cols=5, starting_group=-1):\n",
    "    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(cols * 2, 8))\n",
    "    rainbow = matplotlib.colors.LinearSegmentedColormap.from_list(name=\"rainbow\", colors=['white', 'magenta', 'blue', 'cyan', 'lime', 'yellow', 'orange', 'red'])\n",
    "\n",
    "    for col in range(cols):\n",
    "        for row in range(rows):\n",
    "            if row == 0:\n",
    "                ax[row][col].set_title(f\"Group {starting_group + col}\")\n",
    "\n",
    "            # Global settings for all subplots\n",
    "            ax[row][col].set_xticklabels([])\n",
    "            ax[row][col].set_yticklabels([])\n",
    "            ax[row][col].tick_params(left=False, bottom= False)\n",
    "\n",
    "            if col >= len(paths) or row >= len(paths[col]):\n",
    "                continue\n",
    "\n",
    "            path = paths[col][row]\n",
    "            data = np.fromfile(path, sep=\" \")\n",
    "\n",
    "            data = np.reshape(data, (data_type[\"x\"] * data_type[\"y\"], 3))\n",
    "            data = np.swapaxes(data, 0, 1)\n",
    "            x = data[0].reshape((data_type[\"x\"], data_type[\"y\"]))\n",
    "            y = data[1].reshape((data_type[\"x\"], data_type[\"y\"]))\n",
    "            z = data[2].reshape((data_type[\"x\"], data_type[\"y\"]))\n",
    "\n",
    "            c = ax[row][col].pcolormesh(x, y, z, cmap=rainbow, vmin=0, vmax=0.30)\n",
    "            ax[row][col].axis([data_type[\"xlow\"], data_type[\"xhigh\"], data_type[\"ylow\"], data_type[\"yhigh\"]])\n",
    "\n",
    "            # fig.suptitle('Hi', fontsize=16, fontweight='bold', y=1.02)\n",
    "            fig.suptitle(f\"Batch #{batch}\", fontsize=16, fontweight='bold')\n",
    "\n",
    "\n",
    "            # fig.colorbar(c, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DBSCAN algorithm has been tested to work best at around 1000 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_index = 0\n",
    "num_data = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code stores the datapoints of each PDF file into a Python dictionary so that the data can be easily retrieved while the DBSCAN algorithm runs. It reads all the files that are inside the working directory (which was set earlier), starting from the file located at the `starting_index` position and storing `num_data` number of datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = sorted(os.listdir())\n",
    "zMap = {}\n",
    "for i in tqdm(range(starting_index, starting_index + (num_data))):\n",
    "    arr = np.fromfile(file_list[i], sep=\" \")[2::3]\n",
    "    arr = arr.reshape(data_type[\"x\"], data_type[\"y\"])\n",
    "    arr = skimage.measure.block_reduce(arr, (2, 2), np.mean).flatten()\n",
    "    zMap[i - starting_index] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(pathA, pathB):\n",
    "    return np.sum(np.abs(np.subtract(zMap[int(pathA[0])], zMap[int(pathB[0])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is responsible for actually conducting the DBSCAN algorithm. For documentation on scikit-learn's DBSCAN algorithm, please refer to [this link](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html). For 1000 datasets, an epsilon value between 23 to 26 has been tested to be the most ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global string_seqs\n",
    "string_seqs = np.arange(0, num_data).reshape(-1, 1)\n",
    "clustered_dataset = DBSCAN(eps = 23, metric=metric, n_jobs=-1).fit(X=string_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_group = min(clustered_dataset.labels_)\n",
    "max_group = max(clustered_dataset.labels_)\n",
    "print(f\"There are {max_group - min_group + 1} groups present, ranging from Group {min_group} to Group {max_group}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = {}\n",
    "label_categories = {}\n",
    "for i in range(len(clustered_dataset.labels_)):\n",
    "    label = clustered_dataset.labels_[i]\n",
    "\n",
    "    if label not in total_count:\n",
    "        total_count[label] = 0\n",
    "    if label not in label_categories:\n",
    "        label_categories[label] = []\n",
    "        \n",
    "    total_count[label] += 1\n",
    "    label_categories[label].append(starting_index + i)\n",
    "\n",
    "groups = []\n",
    "\n",
    "for key in sorted(total_count.keys()):\n",
    "    print(f\"Group {key}: {total_count[key]} found\")\n",
    "\n",
    "    curr_group = []\n",
    "    for i in range(total_count[key]):\n",
    "        curr_group.append(file_list[label_categories[key][i]])\n",
    "    \n",
    "    groups.append(curr_group)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_folder = os.path.join(output_dir, f\"batch_{batch_num}\")\n",
    "\n",
    "if not os.path.exists(batch_folder):\n",
    "    os.makedirs(batch_folder)\n",
    "\n",
    "    for i in range(min_group, max_group + 1):\n",
    "        os.makedirs(os.path.join(batch_folder, f\"group_{i}\"))\n",
    "\n",
    "plotGroupPDF(groups, batch_num, 5, max_group - min_group + 1, min_group)\n",
    "plt.savefig(f\"{output_dir}/batch_{batch_num}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, max_group - min_group + 1):\n",
    "    curr_group_num = i + min_group\n",
    "    for file_name in groups[i]:\n",
    "        shutil.move(f\"{data_dir}/{file_name}\", f\"{output_dir}/batch_{batch_num}/group_{curr_group_num}/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dir = \"/home/gcl/TT/sylvesterseo/bsl/strong_motion_batches_negative\"\n",
    "\n",
    "folder_list = sorted(list(filter(lambda x: not \".png\" in x, os.listdir(output_dir))), key=lambda x: int(x.split(\"_\")[1]))\n",
    "\n",
    "for f in folder_list:\n",
    "    if \"group_-1\" in os.listdir(f\"{output_dir}/{f}\"):\n",
    "        graph_path = os.path.join(negative_dir, f)\n",
    "        os.makedirs(graph_path)\n",
    "        os.chdir(f\"{output_dir}/{f}/group_-1\")\n",
    "        for img in os.listdir():\n",
    "            plotPDF(img)\n",
    "            plt.savefig(f\"{negative_dir}/{f}/{img}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
